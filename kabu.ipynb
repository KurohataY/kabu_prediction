{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suffering-dragon",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import requests\n",
    "from datetime import datetime\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Dense, LSTM, Dropout, Flatten\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "\n",
    "from fbprophet import Prophet\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alpine-possession",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 　https://kabuoji3.comから株データを取得\n",
    "def get_dfs(stock_number):\n",
    "    dfs = []\n",
    "#     取得データの西暦\n",
    "    year = [2015,2016,2017,2018,2019,2020,2021] \n",
    "    for y in year:\n",
    "        url = 'https://kabuoji3.com/stock/{}/{}/'.format(stock_number,y)\n",
    "        headers = {\n",
    "             \"User-Agent\":  \"\"\n",
    "        }\n",
    "        soup = BeautifulSoup(requests.get(url, headers = headers).content,'html.parser')\n",
    "        tag_tr = soup.find_all('tr')\n",
    "        head = [h.text for h in tag_tr[0].find_all('th')]\n",
    "            \n",
    "        data = []\n",
    "        for i in range(1,len(tag_tr)):\n",
    "            data.append([d.text for d in tag_tr[i].find_all('td')])\n",
    "        df = pd.DataFrame(data, columns = head)\n",
    "        \n",
    "        col = ['始値','高値','安値','終値','出来高','終値調整']\n",
    "        for c in col:\n",
    "            df[c] = df[c].astype(float)\n",
    "        df['日付'] = [datetime.strptime(i,'%Y-%m-%d') for i in df['日付']]\n",
    "        dfs.append(df)\n",
    "    return dfs\n",
    "\n",
    "def concatenate(dfs):\n",
    "    data = pd.concat(dfs,axis=0)\n",
    "    data = data.reset_index(drop=True)\n",
    "    col = ['始値','高値','安値','終値','出来高','終値調整']\n",
    "    for c in col:\n",
    "        data[c] = data[c].astype(float)\n",
    "    return data\n",
    "\n",
    "# \n",
    "def create_chart(csv):\n",
    "    print(csv)\n",
    "    df = pd.read_csv(csv)\n",
    "    df = df.drop(['出来高','終値調整'], axis = 1)\n",
    "    df.head()\n",
    "    df.columns = ['date', 'open', 'high', 'low', 'close']\n",
    "\n",
    "    x = np.arange(len(df['date']))\n",
    "\n",
    "    interval = 20\n",
    "    vals = [df.index[i*interval] for i in range(len(df)//interval+1)]\n",
    "    labels = [df.loc[i*interval,'date'] for i in range(len(df)//interval +1)]\n",
    "\n",
    "    fig = go.Figure(\n",
    "            data=go.Candlestick(\n",
    "                    x = x,\n",
    "                    open=df['open'],\n",
    "                    high=df['high'],\n",
    "                    low=df['low'],\n",
    "                    close=df['close'],\n",
    "                    hovertext= ['date:{}<br>open:{}<br>high:{}<br>low:{}<br>close:{}'\n",
    "                                       .format(df.loc[i,'date'],df.loc[i,'open'],df.loc[i,'high'],df.loc[i,'low'],df.loc[i,'close']) for i in range(len(df))] ,\n",
    "                    hoverinfo=\"text\"),\n",
    "            layout = go.Layout(\n",
    "                    xaxis = dict(\n",
    "                        ticktext = labels,\n",
    "                        tickvals = vals,\n",
    "                        tickangle=-45\n",
    "                    ),\n",
    "            )\n",
    "    )\n",
    "    fig.show()\n",
    "    \n",
    "# 全結合モデル作成\n",
    "def create_model_feed_forward():\n",
    "    model_1 = Sequential()\n",
    "    model_1.add(Dense(5, activation='relu', input_shape=(20,)))\n",
    "    model_1.add(Dropout(0.5))\n",
    "    model_1.add(Dense(1, activation='linear'))\n",
    "    model_1.summary()\n",
    "    model_1.compile(optimizer='adam',\n",
    "               loss='mse',\n",
    "               metrics=['mae'])\n",
    "    return model_1\n",
    "\n",
    "# LSTMモデル作成\n",
    "def create_model_lstm():\n",
    "    model_2 =Sequential()\n",
    "    model_2.add(LSTM(10,\n",
    "                 dropout=0.2,\n",
    "                 recurrent_dropout=0.2,\n",
    "                 input_shape=(20,1)))\n",
    "    model_2.add(Dense(5, activation='relu'))\n",
    "    model_2.add(Dropout(0.5))\n",
    "    model_2.add(Dense(1, activation='linear'))\n",
    "    model_2.summary()\n",
    "    model_2.compile(optimizer='adam',\n",
    "               loss='mse',\n",
    "               metrics=['mae'])\n",
    "    return model_2\n",
    "    \n",
    "def getInputLabel(data, period=20):\n",
    "    period = period\n",
    "    input_tensor = []\n",
    "    label_tensor = []\n",
    "    for i in range(0, len(data) - period, 1):\n",
    "        input_tensor.append(data.values[i:i + period,0])\n",
    "        label_tensor.append(data.values[i + period,0])\n",
    "    input_tensor = np.array(input_tensor)\n",
    "    label_tensor = np.array(label_tensor)\n",
    "    return input_tensor, label_tensor\n",
    "\n",
    "# prophetモデルの実行\n",
    "def prophet(csv):\n",
    "    df_prophet = pd.read_csv(csv)\n",
    "    model = Prophet()\n",
    "    model.fit(df_prophet.rename(columns={\"日付\" : \"ds\", \"終値調整\" : \"y\"}))\n",
    "\n",
    "    future_data = model.make_future_dataframe(periods=365, freq = 'd')\n",
    "    future_data = future_data[future_data['ds'].dt.weekday < 5]\n",
    "\n",
    "    forecast_data = model.predict(future_data)\n",
    "    print(csv)\n",
    "    model.plot(forecast_data).savefig(\"prophet/image/\" + csv.replace('.csv', '').replace('kabu_csv/', ''))\n",
    "#     model.plot_components(forecast_data).savefig(\"prophet/image/\" + csv.replace('.csv', '').replace('kabu_csv/', ''))\n",
    "    forecast_data.to_csv(\"prophet/csv/\" + csv.replace('kabu_csv/', ''))\n",
    "#     model.plot_components(forecast_data)\n",
    "\n",
    "# ランダムフォレスト\n",
    "def random_forest():\n",
    "    return RandomForestRegressor(n_estimators=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "determined-gossip",
   "metadata": {},
   "outputs": [],
   "source": [
    "#作成したコードリストを読み込む\n",
    "code_list = pd.read_csv('code_list.csv')\n",
    "\n",
    "#複数のデータフレームをcsvで保存\n",
    "for i in range(len(code_list)):\n",
    "    k = code_list.loc[i,'code']\n",
    "    v = code_list.loc[i,'name']\n",
    "    print(k,v)\n",
    "    dfs = get_dfs(k)\n",
    "    data = concatenate(dfs) \n",
    "    data.to_csv('kabu_csv/{}-{}.csv'.format(k,v), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "linear-category",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_list = glob.glob('kabu_csv/*.csv')\n",
    "for csv in csv_list:\n",
    "    create_chart(csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "protective-cardiff",
   "metadata": {},
   "outputs": [],
   "source": [
    "for csv in csv_list:\n",
    "    prophet(csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reported-universal",
   "metadata": {},
   "outputs": [],
   "source": [
    "for csv in csv_list:\n",
    "    data = pd.read_csv(csv)\n",
    "    pre_df = pd.DataFrame(data[\"日付\"], columns=[\"日付\"])\n",
    "\n",
    "    pre_df[\"平均値（高安）\"] = (data[\"高値\"].values+ data[\"安値\"].values) /2\n",
    "    pre_df[\"平均値（始終）\"] = (data[\"始値\"].values+ data[\"終値\"].values) /2\n",
    "\n",
    "    pre_df[\"前日比（高安）\"] = pre_df[\"平均値（高安）\"].diff()\n",
    "    pre_df[\"前日比（始終）\"] = pre_df[\"平均値（始終）\"].diff()\n",
    "\n",
    "    pre_df[\"前日比（高安）\"] = pre_df[\"前日比（高安）\"].fillna(pre_df[\"前日比（高安）\"].mean())\n",
    "    pre_df[\"前日比（始終）\"] = pre_df[\"前日比（始終）\"].fillna(pre_df[\"前日比（始終）\"].mean())\n",
    "\n",
    "    tmp = pd.merge(data, pre_df).drop('日付', axis=1)\n",
    "    tmp = tmp- tmp.mean()\n",
    "    tmp = tmp/tmp.std()\n",
    "    \n",
    "    input_tensor, label_tensor = getInputLabel(data = tmp)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(input_tensor, label_tensor, test_size=0.2,random_state=100, shuffle = False)\n",
    "    earlystopping = EarlyStopping(monitor='loss', patience=5)\n",
    "    \n",
    "    model_1 = create_model_feed_forward()\n",
    "    model_1.fit(X_train, y_train, batch_size=10, epochs=50, callbacks=[earlystopping])\n",
    "    score = model_1.evaluate(X_train, y_train,verbose=1)\n",
    "\n",
    "    print(\"Test loss:\", score[0])\n",
    "    print(\"Test accuracy:\", score[1])\n",
    "    print('\\n')\n",
    "    print(\"全結合: \" + csv)\n",
    "    print(model_1.evaluate(X_test, y_test))\n",
    "    print('\\n')\n",
    "    \n",
    "    plt.figure()\n",
    "    predicted = model_1.predict(X_test)\n",
    "    result = pd.DataFrame(predicted)\n",
    "    result.columns = ['predict']\n",
    "    result['actual'] = y_test\n",
    "    result.plot()\n",
    "    plt.savefig(\"feed_forward/image/\" + csv.replace('.csv', '').replace('kabu_csv/', ''))\n",
    "    plt.show()\n",
    "   \n",
    "    \n",
    "    print('\\n')\n",
    "    \n",
    "    model_2 = create_model_lstm()\n",
    "\n",
    "    model_2.fit(X_train[:,:,np.newaxis], y_train, batch_size=10, epochs=50, callbacks=[earlystopping])\n",
    "    \n",
    "#     # 予測値算出\n",
    "#     predicted = model_2.predict(X_test[:,:,np.newaxis])\n",
    "#     result = pd.DataFrame(predicted)\n",
    "#     result.columns = ['predict']\n",
    "#     result['actual'] = y_test\n",
    "#     result.plot().savefig(\"lstm/image/\" + csv.replace('.csv', '').replace('kabu_csv/', ''))\n",
    "#     plt.show()\n",
    "    \n",
    "    # 予測結果を保存する行列\n",
    "    future_pred = input_tensor[:,0].copy()\n",
    "\n",
    "    # 予測期間は観測値の終端から3年間を設定\n",
    "    pred_time_length = 12*3\n",
    "\n",
    "    for tmp in range(pred_time_length):\n",
    "        # 観測結果の最後尾から予測に使うデータをピックアップ\n",
    "        X_future_pred = future_pred[-1*20:]\n",
    "        # 予測\n",
    "        y_future_pred = model_2.predict( X_future_pred.reshape(1,20,1) )\n",
    "        # 予測値をfuture_predの最後尾に追加\n",
    "        future_pred = np.append(future_pred, y_future_pred)\n",
    "        #print(y_future_pred ,  future_pred[-5:])\n",
    "\n",
    "    # プロット\n",
    "    fig2 = plt.figure()\n",
    "    plt.plot(input_tensor[:,0], color='blue',  label=\"observed\")  # 実測値\n",
    "    plt.plot(range(len(input_tensor),len(input_tensor)+pred_time_length), future_pred[-1*pred_time_length:],  color='red',  label=\"feature pred\")   # 予測値\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "    fig2.savefig(\"lstm/image/\" + csv.replace('.csv', '').replace('kabu_csv/', ''))\n",
    "\n",
    "    score = model_2.evaluate(X_train[:,:,np.newaxis], y_train, verbose=1)\n",
    "    print(\"Test loss:\",score[0])\n",
    "    print(\"Test accuracy:\",score[1])\n",
    "\n",
    "    print('\\n')\n",
    "    print(\"lstm: \" + csv)\n",
    "    print(model_2.evaluate(X_test[:,:,np.newaxis], y_test))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "personalized-newsletter",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3 = random_forest()\n",
    "df_ran_result = pd.DataFrame()\n",
    "for csv in csv_list:\n",
    "    df_ran = pd.read_csv(csv)\n",
    "    df_ran_result[csv.replace('.csv', '').replace('kabu_csv/', '')] = df_ran[\"終値調整\"].diff().drop(0)\n",
    "df_ran_result = df_ran_result.fillna(df_ran_result.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "literary-contemporary",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df_ran_result[df_ran_result.columns.values]\n",
    "y=df_ran_result[\"\"]\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "driving-wheel",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "model_3.fit(x_train,y_train)\n",
    "y_pred=model_3.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "explicit-original",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_imp = pd.Series(model_3.feature_importances_,index=[df_ran_result.columns.values]).sort_values(ascending=False)\n",
    "print(feature_imp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thousand-beauty",
   "metadata": {},
   "outputs": [],
   "source": [
    "# valueX=\n",
    "# pred=model_3.predict(valueX)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
